The **PST-RGB: Penn Subterranean Thermal RGB Dataset** is a supplementary part of the [PST900 RGB-T](https://datasetninja.com/pst900-rgbt) dataset. The PST-RGB consists of 3359 RGB images with per-pixel human annotations of 4 visible artifacts: *fire extinguisher*, *backpack*, *hand drill*, *rescue randy*, driven by the requirements of the [DARPA Subterranean Challenge](https://www.subtchallenge.com/). The sensor head includes a Stereolabs ZED Mini stereo camera and a FLIR Boson 320 camera, and a calibration procedure is designed to obtain camera intrinsics and system extrinsics. The dataset is collected from various environments, including the Number 9 Coal Mine in Lansford, PA, cluttered indoor and outdoor spaces.

<img src="https://github.com/dataset-ninja/pst900-rgbt/assets/78355358/8935aa78-f0a3-427f-a8e1-01ffa2d6ff93" alt="image" width="800">

In their work, the authors propose long-wave infrared (LWIR) imagery as a viable supporting modality for semantic segmentation using learning-based techniques. They address the issue of RGB-thermal camera calibration by introducing a passive calibration target and procedure that is both portable and easy to use.

The ability to parse raw imagery and ascertain pixel-wise and region-wise semantic information is desirable for environment perception enabling advanced robot autonomy. Semantic segmentation is a major subject of robotics research with applications ranging from medicine and agriculture to autonomous vehicles. Convolutional neural networks (CNNs) have been popularly applied to image classification tasks, demonstrating significant improvements over classical methods. Recently, the focus has shifted to semantic segmentation from RGB imagery, driven by the growth in autonomous vehicle research.

The authors highlight the increasing accessibility of thermal cameras, once primarily used by the military, and propose their usage in challenging environments, particularly those with visibility and illumination limitations, such as underground tunnels, mines, and caves. They argue that long-wave infrared spectrum information can enhance segmentation accuracy in such environments, especially since it is not dependent on visible spectrum illumination. The authors demonstrate that the fusion of thermal information improves the segmentation of objects without distinct thermal signatures.

The authors acknowledge that collecting large amounts of RGB data and obtaining accurate per-pixel human annotations is more feasible than doing so for calibrated and aligned RGB-Thermal data. They design a network with an independent RGB stream that can be trained without thermal data and introduce the thermal modality to improve the results. The proposed sequential, dual stream architecture draws influence from ResNet-18, UNet, and ERFNet, demonstrating efficiency, flexibility, and accuracy on their dataset.
